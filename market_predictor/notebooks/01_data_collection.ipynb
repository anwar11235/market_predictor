{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Predictor: Data Collection\n",
    "\n",
    "This notebook demonstrates the data collection process from various sources:\n",
    "1. Market Data (price and volume)\n",
    "2. News Data (financial news and sentiment)\n",
    "3. Social Media Data (Reddit and Twitter)\n",
    "4. Macroeconomic Data (economic indicators)\n",
    "\n",
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.data import DataLoader\n",
    "from src.integrations import create_data_clients\n",
    "from src.utils import setup_project_logger\n",
    "from config import Config, load_validated_config\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "Load and validate the project configuration from `config/parameters.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_validated_config('config/parameters.yaml')\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_project_logger('data_collection')\n",
    "logger.info('Starting data collection process')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Market Data Collection\n",
    "\n",
    "Collect market data (OHLCV) for S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_loader = DataLoader(config)\n",
    "\n",
    "# Get market data\n",
    "market_data = data_loader.get_market_data()\n",
    "\n",
    "# Display basic information\n",
    "print(\"Market Data Info:\")\n",
    "print(market_data.info())\n",
    "\n",
    "# Plot price and volume\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Price plot\n",
    "market_data['Close'].plot(ax=ax1, title='S&P 500 Price')\n",
    "ax1.set_ylabel('Price')\n",
    "\n",
    "# Volume plot\n",
    "market_data['Volume'].plot(ax=ax2, title='Trading Volume')\n",
    "ax2.set_ylabel('Volume')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. News Data Collection\n",
    "\n",
    "Collect and analyze financial news from multiple sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize data clients\n",
    "clients = create_data_clients(config)\n",
    "\n",
    "# Get news data from different sources\n",
    "news_data = {}\n",
    "\n",
    "if 'newsapi' in clients:\n",
    "    news_data['newsapi'] = clients['newsapi'].get_market_news()\n",
    "    \n",
    "if 'alphavantage' in clients:\n",
    "    news_data['alphavantage'] = clients['alphavantage'].get_market_news()\n",
    "    \n",
    "if 'finnhub' in clients:\n",
    "    news_data['finnhub'] = clients['finnhub'].get_market_news()\n",
    "\n",
    "# Display news statistics\n",
    "for source, data in news_data.items():\n",
    "    print(f\"\\n{source.upper()} News Statistics:\")\n",
    "    print(f\"Total articles: {len(data)}\")\n",
    "    if 'sentiment_score' in data.columns:\n",
    "        print(f\"Average sentiment: {data['sentiment_score'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Social Media Data Collection\n",
    "\n",
    "Collect and analyze social media sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get social media data\n",
    "social_data = {}\n",
    "\n",
    "if 'reddit' in clients:\n",
    "    # Get Reddit sentiment\n",
    "    social_data['reddit'] = clients['reddit'].get_subreddit_sentiment('wallstreetbets')\n",
    "    \n",
    "if 'twitter' in clients:\n",
    "    # Get Twitter sentiment\n",
    "    social_data['twitter'] = clients['twitter'].search_cashtag('SPY')\n",
    "\n",
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for source, data in social_data.items():\n",
    "    if 'sentiment_score' in data.columns:\n",
    "        sns.histplot(data=data, x='sentiment_score', label=source, alpha=0.5)\n",
    "\n",
    "plt.title('Sentiment Distribution by Source')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Macroeconomic Data Collection\n",
    "\n",
    "Collect and analyze macroeconomic indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get macro data\n",
    "macro_data = data_loader.get_macro_data()\n",
    "\n",
    "# Display macro data info\n",
    "print(\"Macroeconomic Data Info:\")\n",
    "print(macro_data.info())\n",
    "\n",
    "# Plot key indicators\n",
    "key_indicators = ['GDP', 'UNRATE', 'CPI', 'FEDFUNDS']\n",
    "fig, axes = plt.subplots(len(key_indicators), 1, figsize=(15, 15))\n",
    "\n",
    "for i, indicator in enumerate(key_indicators):\n",
    "    if indicator in macro_data.columns:\n",
    "        macro_data[indicator].plot(ax=axes[i], title=f'{indicator} Over Time')\n",
    "        axes[i].set_ylabel(indicator)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Analysis\n",
    "\n",
    "Analyze the quality of collected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import DataQualityMetrics\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values Analysis:\")\n",
    "print(\"\\nMarket Data:\")\n",
    "print(DataQualityMetrics.calculate_missing_percentages(market_data))\n",
    "\n",
    "print(\"\\nMacro Data:\")\n",
    "print(DataQualityMetrics.calculate_missing_percentages(macro_data))\n",
    "\n",
    "# Check data staleness\n",
    "print(\"\\nData Staleness:\")\n",
    "staleness = DataQualityMetrics.calculate_data_staleness(market_data, market_data.index.name)\n",
    "print(f\"Market data staleness: {staleness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Processed Data\n",
    "\n",
    "Save the collected and processed data for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "\n",
    "# Save processed data\n",
    "market_data.to_parquet('data/processed/market_data.parquet')\n",
    "macro_data.to_parquet('data/processed/macro_data.parquet')\n",
    "\n",
    "# Save news and social data\n",
    "for source, data in news_data.items():\n",
    "    data.to_parquet(f'data/processed/news_{source}.parquet')\n",
    "\n",
    "for source, data in social_data.items():\n",
    "    data.to_parquet(f'data/processed/social_{source}.parquet')\n",
    "\n",
    "logger.info('Data collection and processing completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Proceed to `02_feature_engineering.ipynb` for feature generation\n",
    "2. Document any data quality issues encountered\n",
    "3. Consider additional data sources if needed"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
